---
layout:     post
title:      机器学习中的线性代数之矩阵求导
subtitle:   
date:       2019-09-09
author:     Lij
header-img: img/post-bg-universe.jpg
catalog: true
tags:
    - 机器学习
    - 线性代数
---

**矩阵求导(Matrix Derivative)** **也称为矩阵微分(Matrix Differential)**,在机器学习,图像处理,最优化等领域的公式推导经常用到.

矩阵的微积分本质上是多元变量的微积分问题,只是应用在矩阵空间上而已

根据Y与X的不同类型(实值,向量,矩阵)给出如下表中的表示:

![image-20191129162928344](/Users/lijian/Library/Application Support/typora-user-images/image-20191129162928344.png)

下面我们根据分子的布局（即X的类型）来介绍矩阵的导数求解

#### 布局约定(Layout conventions)

事实上,所有求导的法则都可以从最基本的求导规则推导出来.不同文献,不同样子求导的结果有时候就差一个转置.于是我们得先说说求导的两个派别(布局).



由向量关于向量的求导可以得出两种矛盾的表示:结果表示为$m\times n$矩阵,也就是把y表示成列向量x 表示为行向量或者反过来表示的问题.

**布局（Layout）**：在矩阵求导中有两种布局，分别为**分母布局(denominator layout)**和**分子布局(numerator layout)**。这两种不同布局的求导规则是不一样的。

向量 $$，关于标量xx 的求导，

在分子布局下，为：
∂y∂x=⎡⎣⎢⎢⎢⎢⎢⎢∂y1∂x∂y2∂x⋮∂yn∂x⎤⎦⎥⎥⎥⎥⎥⎥(1)
(1)∂y∂x=[∂y1∂x∂y2∂x⋮∂yn∂x]

而在分母布局下，为：
∂y∂x=[∂y1∂x∂y2∂x⋯∂yn∂x](2)
(2)∂y∂x=[∂y1∂x∂y2∂x⋯∂yn∂x]

通过观察和推导我们可以知道，分子布局和分母布局之间刚好差一个转置，即在分子布局下与原来YY相同，而在分母布局下差一个转置。
对于正切矩阵∂y∂x∂y∂x采用分母布局，即Y⊤Y⊤，很不符合表达的习惯，所以本文中我们采用的是分子布局。
